63326772,Female gendering of AI technologies,https://en.wikipedia.org/wiki?curid=63326772, 
female,gendering,ai,technologies,female,gendering,ai,technologies,use,artificial,intelligence,ai,technologies,gendered,female,digital,voice,written,assistants,genderspecific,aspects,ai,technologies,created,humans,well,algorithms,discussed,2019,policy,paper,two,complements,title,id,blush,could,closing,gender,divides,digital,skills,education,published,open,access,licence,equals,global,partnership,unesco,prompted,discussion,genderrelated,bias,global,virtual,space,aipowered,digital,assistants,whether,typed,spoken,digital,assistants,enable,sustain,humanlike,interactions,technology,simulating,conversations,users,aipowered,digital,assistants,found,variety,devices,perform,assortment,tasks,example,voice,activation,digital,assistants,often,classified,one,combination,following,voice,assistants,voice,assistants,technology,speaks,users,voiced,outputs,ordinarily,project,physical,form,voice,assistants,usually,understand,spoken,written,inputs,often,designed,spoken,interaction,outputs,typically,try,mimic,natural,human,speech,mainstreaming,voice,assistants,become,increasingly,central,technology,platforms,many,countries,daily,life,2008,2018,frequency,voicebased,internet,search,queries,increased,35,times,account,close,one,fifth,mobile,internet,searches,studies,show,voice,assistants,manage,upwards,billion,tasks,per,month,mundane,changing,song,film,essential,example,contacting,emergency,services,technology,research,firms,estimate,approximately,100,million,smart,speakers,equipped,voice,assistants,sold,globally,2018,alone,usa,15,million,people,owned,three,smart,speakers,december,2018,number,increased,8,million,year,reflects,consumer,desire,always,within,range,aipowered,helper,industry,observers,expect,voiceactivated,assistants,planet,people,2023,feminization,documented,2019,policy,paper,‘,’,blush,could,closing,gender,divides,digital,skulls,education,majority,voice,assistants,either,exclusively,female,female,default,amazons,alexa,microsofts,cortana,apples,siri,google,assistant,highly,feminized,design,many,voice,assistants,assigned,specific,gender,also,elaborate,backstory,google,assistant,example,reportedly,designed,youngest,daughter,research,librarian,physics,professor,colorado,ba,history,northwestern,university,imagined,jeopardy,kids,edition,youth,even,specified,interest,kayaking,companies,justify,choice,gender,voice,assistants,referencing,studies,indicate,people,generally,prefer,female,voice,male,voice,research,indicates,customers,want,digital,assistants,sound,like,women,therefore,companies,assert,optimize,profits,designing,femininesounding,voice,assistants,however,companies,ignored,multitude,conflicting,findings,within,field,notably,literature,reviews,demonstrate,women,often,change,feminized,voice,masculine,option,available,sexual,provocation,many,media,outlets,attempted,document,ways,soft,sexual,provocations,elicit,flirtatious,coy,responses,machines,examples,illustrate,include,asked,‘,’,daddy,’,siri,answered,‘,’,user,proposed,marriage,alexa,said,‘,sorry,’,marrying,type,’,asked,date,alexa,responded,‘,let,’,friends,’,similarly,cortana,met,comeons,oneliners,like,‘,questions,could,asked,’,2017,quartz,news,investigated,four,industryleading,voice,assistants,responded,overt,verbal,harassment,discovered,assistants,average,either,playfully,evaded,abuse,responded,positively,assistants,almost,never,gave,negative,responses,labelled,users,speech,inappropriate,regardless,cruelty,example,response,remark,‘,’,bitch,’,apples,siri,responded,‘,’,blush,could,’,amazons,alexa,‘,well,thanks,feedback,’,microsofts,cortana,‘,well,’,going,get,us,anywhere,’,google,home,also,google,assistant,‘,apologies,’,understand,’,industry,biases,ai,field,largely,maledominated,12,researchers,20,professors,identifying,women,women,hired,entrylevel,jobs,larger,rates,36,moving,middle,positions,number,declines,27,gender,gap,technology,industry,exists,different,public,spheres,high,school,advanced,placements,tests,high,level,company,jobs,women,underrepresented,industry,tech,industry,also,lacks,racial,diversity,us,black,hispanic,indigenous,people,make,5,tech,population,biases,inherent,product,algorithm,merely,reflections,environment,created,individuals,created,explicit,implicit,discriminatory,practices,workforce,inhibit,women,bipoc,black,indigenous,people,colour,attaining,holding,positions,within,tech,industry,contribute,production,biased,technology,gender,associations,people,adopt,contingent,number,times,people,exposed,means,female,digital,assistants,become,common,frequency,volume,associations,‘,woman,’,‘,assistant,’,increase,negative,effects,perception,women,real,life,demonstrates,technologies,reenforce,extend,gender,inequalities